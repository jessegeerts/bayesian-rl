{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([-.3, .5])\n",
    "\n",
    "beta = (1/.2)**2  # Precision parameter (noise variance)\n",
    "alpha = 2.  # precision of prior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(x, a):\n",
    "    return a[0] + a[1] * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(a, beta, n=1):\n",
    "    x = np.random.uniform(-1, 1, n)\n",
    "    t = get_y(x, a) + np.random.normal(0, 1/ np.sqrt(beta))\n",
    "    return x, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_synthetic_data(a,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the prior \n",
    "w0, w1 = np.mgrid[-1:1:.01, -1:1:.01]\n",
    "pos = np.empty(w0.shape + (2,))\n",
    "pos[:, :, 0] = w0; pos[:, :, 1] = w1\n",
    "rv = multivariate_normal([0, 0], (1/ alpha) * np.eye(2))\n",
    "\n",
    "plt.imshow(rv.pdf(pos), extent=[-1, 1, -1 ,1], cmap='inferno')\n",
    "\n",
    "plt.title('Prior distribution')\n",
    "\n",
    "plt.xlabel('w_0')\n",
    "plt.ylabel('w_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = rv.rvs(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[4,4])\n",
    "\n",
    "x = np.linspace(-1, 1, 50)\n",
    "\n",
    "for s in samples:\n",
    "    plt.plot(x, s[0] + x * s[1])\n",
    "\n",
    "plt.xlim([-1,1])\n",
    "plt.ylim([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we observe a single data point \n",
    "x, t = generate_synthetic_data(a, beta, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can therefore evaluate the likelihood function p(t| x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_func(t, x, w, beta):\n",
    "    rv = multivariate_normal(get_y(x, w), 1/beta)\n",
    "    return rv.pdf(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_mat = np.empty(w1.shape)\n",
    "for i, wx in enumerate(w1[0]):\n",
    "    for j, wy in enumerate(w1[0]):\n",
    "        likelihood = likelihood_func(t[0], x[0], np.array([wx, wy]), beta)\n",
    "        likelihood_mat[i, j] = likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(likelihood_mat, extent=[-1, 1, -1, 1])\n",
    "\n",
    "plt.scatter(a[0], a[1], marker='+', c='white', s=100)\n",
    "plt.title('Likelihood')\n",
    "\n",
    "\n",
    "plt.xlabel('w_0')\n",
    "plt.ylabel('w_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we want to compute a posterior distribution by multiplying the likelihood function by the prior, \n",
    "# and normalising. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the posterior \n",
    "\n",
    "# new parameters (can just update parameters because we use a conjugate prior)\n",
    "S_N_inv = alpha * np.eye(2) + beta * np.outer(np.array([1, x]), np.array([1, x]))\n",
    "S_N = np.linalg.inv(S_N_inv)\n",
    "m = beta * np.matmul(S_N, np.array([1,x])) * t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0, w1 = np.mgrid[-1:1:.01, -1:1:.01]\n",
    "pos = np.empty(w0.shape + (2,))\n",
    "pos[:, :, 0] = w0; pos[:, :, 1] = w1\n",
    "rv = multivariate_normal(m, S_N)\n",
    "\n",
    "plt.imshow(rv.pdf(pos), extent=[-1, 1, -1 ,1], cmap='inferno')\n",
    "plt.scatter(a[0], a[1], marker='+', c='white', s=100)\n",
    "\n",
    "\n",
    "plt.title('Posterior distribution')\n",
    "\n",
    "plt.xlabel('w_0')\n",
    "plt.ylabel('w_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = rv.rvs(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[4,4])\n",
    "\n",
    "xs = np.linspace(-1, 1, 50)\n",
    "\n",
    "for s in posterior_samples:\n",
    "    plt.plot(xs, s[0] + xs * s[1])\n",
    "\n",
    "plt.scatter(x, t, marker='o')    \n",
    "\n",
    "plt.xlim([-1,1])\n",
    "plt.ylim([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we observe a second data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we observe a single data point \n",
    "x2, t2 = generate_synthetic_data(a, beta, 1)\n",
    "\n",
    "# the posterior of the past trial is now the prior:\n",
    "S_N_inv_prior = S_N_inv\n",
    "S_N_prior = S_N\n",
    "m_prior = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_mat = np.empty(w1.shape)\n",
    "for i, wx in enumerate(w1[0]):\n",
    "    for j, wy in enumerate(w1[0]):\n",
    "        likelihood = likelihood_func(t2[0], x2[0], np.array([wx, wy]), beta)\n",
    "        likelihood_mat[i, j] = likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(likelihood_mat, extent=[-1, 1, -1, 1])\n",
    "\n",
    "plt.scatter(a[0], a[1], marker='+', c='white', s=100)\n",
    "plt.title('Likelihood')\n",
    "\n",
    "\n",
    "plt.xlabel('w_0')\n",
    "plt.ylabel('w_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new parameters (can just update parameters because we use a conjugate prior)\n",
    "S_N_inv = S_N_inv_prior + beta * np.outer(np.array([1, x2]), np.array([1, x2]))\n",
    "S_N = np.linalg.inv(S_N_inv)\n",
    "m = np.matmul(S_N, np.matmul(S_N_inv_prior, m_prior) + beta * np.array([1, x2]) * t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = multivariate_normal(m, S_N)\n",
    "\n",
    "plt.imshow(rv.pdf(pos), extent=[-1, 1, -1 ,1], cmap='inferno')\n",
    "plt.scatter(a[0], a[1], marker='+', c='white', s=100)\n",
    "\n",
    "plt.title('Posterior distribution')\n",
    "\n",
    "plt.xlabel('w_0')\n",
    "plt.ylabel('w_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = rv.rvs(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[4,4])\n",
    "\n",
    "xs = np.linspace(-1, 1, 50)\n",
    "\n",
    "for s in posterior_samples:\n",
    "    plt.plot(xs, s[0] + xs * s[1])\n",
    "\n",
    "plt.scatter([x, x2], [t, t2], marker='o')    \n",
    "\n",
    "plt.xlim([-1,1])\n",
    "plt.ylim([-1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we're not actually interested in the value of w itself but rather in making predictions of t for new values of x. Therefore we need to evaluate the *predictive* distribution.\n",
    "\n",
    "Turns out the predictive distribution is also a gaussian because of result 2.115 in Bishop (convolution of two Gaussian distributions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictive distribution. \n",
    "\n",
    "\n",
    "\n",
    "means = []\n",
    "variances = [] \n",
    "for x in xs:\n",
    "\n",
    "    phi = np.array([1, x])\n",
    "\n",
    "    predictive_mean = np.dot(m, phi)\n",
    "    predictive_var = 1 / beta + np.dot(phi, np.matmul(S_N, phi))\n",
    "\n",
    "    #predictive_dist = multivariate_normal(predictive_mean, predictive_var)\n",
    "    \n",
    "    means.append(predictive_mean)\n",
    "    variances.append(predictive_var)\n",
    "    \n",
    "    \n",
    "means = np.array(means)\n",
    "variances = np.array(variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[4,4])\n",
    "\n",
    "plt.plot(xs, means)\n",
    "plt.fill_between(xs, means - np.sqrt(variances), means + np.sqrt(variances), alpha=.2)\n",
    "plt.plot(xs, get_y(xs, a))\n",
    "\n",
    "plt.xlim([-1,1])\n",
    "plt.ylim([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
